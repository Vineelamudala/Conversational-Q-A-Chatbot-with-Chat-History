**ğŸ“„ RAG Q&A Conversation with PDFs (Chat History Enabled)**

A Retrieval-Augmented Generation (RAG) based conversational application that allows users to upload PDF documents and chat with them, while maintaining conversation history across sessions.

Built using LangChainâ€™s latest runnable architecture, Groq LLM (LLaMA), Hugging Face embeddings, Chroma vector store, and Streamlit for the UI.

________________________________________________________________________

**ğŸš€ Features**

ğŸ“‚ Upload multiple PDF files

ğŸ” Semantic search using vector embeddings

ğŸ§  History-aware RAG (understands follow-up questions)

ğŸ’¬ Persistent chat history per session

âš¡ Fast inference using Groq LLaMA models

ğŸ–¥ï¸ Simple and interactive Streamlit UI

âŒ Hallucination-aware responses (answers only from retrieved context)

________________________________________________________________________

**ğŸ› ï¸ Tech Stack**

Python

LangChain (LCEL & Runnables)

Groq LLM (LLaMA 3.3 â€“ 70B)

Hugging Face Embeddings (all-MiniLM-L6-v2)

Chroma Vector Store

Streamlit

PyPDFLoader

________________________________________________________________________

**ğŸ§  Architecture Overview**

User Query
   â†“
Chat History Aware Retriever
   â†“
Vector Store (Chroma)
   â†“
Relevant Context
   â†“
LLM (Groq - LLaMA)
   â†“
Concise Answer
   â†“
Stored in Session Chat History

________________________________________________________________________

**ğŸ“‚ Project Structure**

â”œâ”€â”€ app.py                  # Streamlit application
â”œâ”€â”€ requirements.txt        # Project dependencies
â”œâ”€â”€ .env.example            # Environment variable template
â”œâ”€â”€ README.md               # Documentation
________________________________________________________________________

**ğŸ§ª How It Works**

Upload one or more PDF files

PDFs are split into chunks

Embeddings are generated using Hugging Face

Stored in Chroma vector database

User asks a question

Retriever fetches relevant context

LLM answers only from retrieved content

Chat history is maintained across queries
________________________________________________________________________

**ğŸ§  Key Concepts Implemented**

Retrieval-Augmented Generation (RAG)

History-aware retrieval

LangChain RunnableWithMessageHistory

Vector similarity search

Controlled context to reduce hallucinations

Session-based memory management
________________________________________________________________________

**ğŸ“˜ Learning Outcomes**

Implemented conversation-aware RAG pipelines

Understood LangChain agent & retriever internals

Learned how to manage chat history with LCEL

Built safe, production-style GenAI applications

Integrated Groq LLMs with LangChain
